{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "pd.set_option('display.max_columns', None)\n",
    "from pyexcelerate import Workbook\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def rev_to_dict(ind,find):\n",
    "#     ind = ind.astype('str')\n",
    "    df = pd.DataFrame(index=ind,data=find.values,columns=[find.name])\n",
    "    df = df.groupby(df.index).first()\n",
    "    dictt =  df.to_dict('index')\n",
    "    return dictt\n",
    "\n",
    "def header_parser(df):\n",
    "\n",
    "    lst = list(df.columns)\n",
    "\n",
    "    value = 0\n",
    "    for index,col in enumerate(lst):\n",
    "        if col is np.nan:\n",
    "            lst[index] = lst[index-1]+str(value)\n",
    "            value +=1\n",
    "        else:\n",
    "            value  = 0\n",
    "\n",
    "    a,b = [],[]\n",
    "    for col in lst:\n",
    "        a.append(col)\n",
    "        b.append(lst.count(col))\n",
    "\n",
    "    a = pd.Series(a)\n",
    "    b = pd.Series(b)\n",
    "    b.name = 'val'    \n",
    "    s  = rev_to_dict(a,b)\n",
    "\n",
    "    ls_k = list(s.keys())\n",
    "\n",
    "    for col in ls_k:\n",
    "        if s[col]['val']>1:\n",
    "            for ind in range(0,s[col]['val']):\n",
    "                for ind_,col_ in enumerate(lst):\n",
    "                    if col_==col:\n",
    "                        lst[ind_] = col_+str(ind)\n",
    "                        break\n",
    "\n",
    "    df.columns = lst\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def save_pyex(path,df):\n",
    "    wb = Workbook()\n",
    "    wb.new_sheet('sheet1',data =  [df.columns.tolist(),]+df.values.tolist())\n",
    "    wb.save(path)\n",
    "\n",
    "    \n",
    "import copy\n",
    "import csv\n",
    "import dask\n",
    "from dask import dataframe as dd \n",
    "from multiprocessing.pool import ThreadPool\n",
    "dask.config.set(pool=ThreadPool(6))\n",
    "\n",
    "def get_arr_from_csv(dir_and_filename):\n",
    "    arr = []\n",
    "    with open(dir_and_filename) as File:\n",
    "        reader = csv.reader(File, delimiter=';', quotechar=',',\n",
    "                            quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in reader:\n",
    "            arr.append(row)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def get_dask_arr(directory,file_data_name,file_meta_name):\n",
    "    arr_mtd = get_arr_from_csv(directory+file_meta_name+'.CSV')\n",
    "    arr_data = get_arr_from_csv(directory+file_data_name+'.CSV')\n",
    "    dict_meta = dict((x[0].strip(),x[1].strip()) for x in arr_mtd if len(x)>3 and x[0]!='COLUMN')\n",
    "    dict_meta_types = dict((x[0].strip(),x[3].strip()) for x in arr_mtd if len(x)>3 and x[0]!='COLUMN')\n",
    "    dfr = pd.DataFrame(data = arr_data,columns = list(dict_meta.values()))\n",
    "    \n",
    "    for ind,col in enumerate(dfr.columns,1):\n",
    "        if types_pnds[dict_meta_types[str(ind)]]=='float64':\n",
    "#             dfr[col] = dfr[col].apply(lambda x:str(x).replace(regex = r'^-$',new = ''))\n",
    "#             dfr[col] = dfr[col].replace(regex=r'-$', value='')\n",
    "            dfr[col] = dfr[col].apply(lambda x:x[-1]+x[:-1] if len(re.findall(r'-$',x))>0 else x)\n",
    "        dfr[col] = dfr[col].astype(types_pnds[dict_meta_types[str(ind)]])\n",
    "    \n",
    "#     sd = dd.from_pandas(dfr, npartitions=100)\n",
    "    sd = dfr\n",
    "    return sd\n",
    "\n",
    "def get_df_gr_pandas(df,index_):\n",
    "    \n",
    "    index_join_group = copy.copy(index_) \n",
    "\n",
    "    vl06_index_join_group_start = copy.copy(index_join_group)\n",
    "    vl06_index_join_group_start.append('ZKFGDOCIN')\n",
    "\n",
    "\n",
    "\n",
    "    print(index_join_group)\n",
    "    \n",
    "    df['gr_index']=''\n",
    "    for ind, col in enumerate(index_join_group):\n",
    "        if ind==len(index_join_group)-1:\n",
    "            df['gr_index'] = df['gr_index'].astype('str')+df[col].astype('str')\n",
    "        else:\n",
    "            df['gr_index'] = df['gr_index'].astype('str')+df[col].astype('str')+'----'\n",
    "\n",
    "    \n",
    "    \n",
    "    potr = df[['gr_index','/BIC/ZMM1Q01']].groupby('gr_index').sum().reset_index()\n",
    "    potr =  potr.rename(columns={\"/BIC/ZMM1Q01\":\"_Потребность,кол-во\"})\n",
    "    potr = potr.set_index('gr_index')\n",
    "    \n",
    "    \n",
    "    potr_usd = df[['gr_index','/BIC/ZMM1A01']].groupby('gr_index').sum().reset_index()\n",
    "    potr_usd =  potr_usd.rename(columns={\"/BIC/ZMM1A01\":\"_Потребность,стоимость,USD\"})\n",
    "    potr_usd = potr_usd.set_index('gr_index')\n",
    "    \n",
    "    ost_raspr = df[['gr_index','/BIC/ZMM1Q22']].groupby('gr_index').sum().reset_index()\n",
    "    ost_raspr =  ost_raspr.rename(columns={\"/BIC/ZMM1Q22\":\"Распределение остатка,кол-во\"})\n",
    "    ost_raspr = ost_raspr.set_index('gr_index')\n",
    "    \n",
    "    \n",
    "    ost_raspr_KZT = df[['gr_index','VALST_KZT']].groupby('gr_index').sum().reset_index()\n",
    "    ost_raspr_KZT =  ost_raspr_KZT.rename(columns={\"VALST_KZT\":\"Сумма распределенного остатка,KZT\"})\n",
    "    ost_raspr_KZT = ost_raspr_KZT.set_index('gr_index')\n",
    "    \n",
    "    ost_raspr_USD = df[['gr_index','VALST_USD']].groupby('gr_index').sum().reset_index()\n",
    "    ost_raspr_USD =  ost_raspr_USD.rename(columns={\"VALST_USD\":\"Сумма распределенного остатка,USD\"})\n",
    "    ost_raspr_USD = ost_raspr_USD.set_index('gr_index')\n",
    "    \n",
    "    \n",
    "    vl_06 = df[df['DOCTYPE'].isin(['VL06'])][['gr_index','ZKFGDOCIN']].groupby('gr_index').sum().reset_index()\n",
    "    vl_06 =  vl_06.rename(columns={\"ZKFGDOCIN\":\"Товар в пути(VL06),кол-во\"})\n",
    "    vl_06 = vl_06.set_index('gr_index')\n",
    "    \n",
    "    znb_5 = df[df['DOCTYPE'].isin(['ZNB5'])][['gr_index','ZKFGDOCIN']].groupby('gr_index').sum().reset_index()\n",
    "    znb_5 =  znb_5.rename(columns={\"ZKFGDOCIN\":\"Товар в пути(ZNB5),кол-во\"})\n",
    "    znb_5 = znb_5.set_index('gr_index')\n",
    "    \n",
    "    \n",
    "    znb_2_3_4 = df[df['DOCTYPE'].isin(['ZNB2','ZNB3','ZNB4'])][['gr_index','ZKFGDOCIN']].groupby('gr_index').sum().reset_index()\n",
    "    znb_2_3_4 =  znb_2_3_4.rename(columns={\"ZKFGDOCIN\":\"Законтрактовано(ZNB2-4-ПртПзк),кол-во\"})\n",
    "    znb_2_3_4 = znb_2_3_4.set_index('gr_index')\n",
    "    \n",
    "    \n",
    "    nb = ar[ar['DOCTYPE'].apply(lambda x: len(re.findall('^NB\\d\\d',str(x)))>0 )][['gr_index','ZKFGDOCIN']].groupby('gr_index').sum().reset_index()\n",
    "    nb =  nb.rename(columns={\"ZKFGDOCIN\":\"Заявка на закуп(NB),кол-во\"})\n",
    "    nb = nb.set_index('gr_index')\n",
    "    \n",
    "    r_rash = df[['gr_index','ZKFGOUT']].groupby('gr_index').sum().reset_index()\n",
    "    r_rash =  r_rash.rename(columns={\"ZKFGOUT\":\"Распределение расхода, кол-во\"})\n",
    "    r_rash = r_rash.set_index('gr_index')\n",
    "    \n",
    "    \n",
    "    r_prih_1 = df[df['/BIC/ZDECADE'].isin(['1'])][['gr_index','ZKFGIN']].groupby('gr_index').sum().reset_index()\n",
    "    r_prih_1 =  r_prih_1.rename(columns={\"ZKFGIN\":\"Распределение прихода 1декада, кол-во\"})\n",
    "    r_prih_1 = r_prih_1.set_index('gr_index')\n",
    "    \n",
    "    r_prih_2 = df[df['/BIC/ZDECADE'].isin(['2'])][['gr_index','ZKFGIN']].groupby('gr_index').sum().reset_index()\n",
    "    r_prih_2 =  r_prih_2.rename(columns={\"ZKFGIN\":\"Распределение прихода 2декада, кол-во\"})\n",
    "    r_prih_2 = r_prih_2.set_index('gr_index')\n",
    "    \n",
    "    r_prih_3 = df[df['/BIC/ZDECADE'].isin(['3'])][['gr_index','ZKFGIN']].groupby('gr_index').sum().reset_index()\n",
    "    r_prih_3 =  r_prih_3.rename(columns={\"ZKFGIN\":\"Распределение прихода 3декада, кол-во\"})\n",
    "    r_prih_3 = r_prih_3.set_index('gr_index')\n",
    "    \n",
    "    \n",
    "    r_prih_sum = df[df['FLAG_DISTR'].isin(['I','N','P','T'])][['gr_index','/BIC/ZCPPVCC']].groupby('gr_index').sum().reset_index()\n",
    "    r_prih_sum =  r_prih_sum.rename(columns={\"/BIC/ZCPPVCC\":\"Сумма распределенного прихода, USD\"})\n",
    "    r_prih_sum = r_prih_sum.set_index('gr_index')\n",
    "    \n",
    "    r_rash_sum = df[df['FLAG_DISTR'].isin(['U','O'])][['gr_index','/BIC/ZCPPVCC']].groupby('gr_index').sum().reset_index()\n",
    "    r_rash_sum =  r_rash_sum.rename(columns={\"/BIC/ZCPPVCC\":\"Сумма распределенного расхода, USD\"})\n",
    "    r_rash_sum = r_rash_sum.set_index('gr_index')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dfr = pd.concat([potr,potr_usd,ost_raspr,ost_raspr_KZT,ost_raspr_USD,vl_06,znb_5,znb_2_3_4,nb,r_rash,r_rash_sum,r_prih_1,r_prih_2,r_prih_3,r_prih_sum],axis = 1)\n",
    "    \n",
    "    dfr = dfr.reset_index()\n",
    "    \n",
    "    for ind,col in enumerate(index_join_group):\n",
    "        dfr[col] = dfr['index'].apply(lambda x: str(x).split('----')[ind])\n",
    "    dfr = dfr.drop(['index'],axis = 1)\n",
    "    \n",
    "    for col in dfr.columns:\n",
    "        if dfr[col].dtype=='float64':\n",
    "            dfr[col].fillna(0,inplace = True)\n",
    "    \n",
    "    \n",
    "    return dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C:\\\\Users\\\\NKedrun\\\\AppData\\\\Local\\\\VirtualStore\\\\'\n",
    "types_pnds = {'CHAR':'category','CUKY':'category','CURR':'float64','FLTP':'float64','NUMC':'category','QUAN':'float64','UNIT':'category','DATS':'category'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = get_dask_arr(directory,'ZPR1OH01','S_ZPR1OH01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt1  = get_df_gr_pandas(df = ar,index_ = ['COMP_CODE','/BIC/ZNPLANT','CALDAY','/BIC/ZRMTRLEAD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind, i in enumerate(np.array_split(dfr,3)) :\n",
    "save_pyex(df=tt1,path=directory+'open_hub_.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potr = ar[['gr_index','/BIC/ZMM1Q01','CALYEAR']].pivot_table(index=['gr_index'],aggfunc='sum',columns=['CALYEAR'],values = ['/BIC/ZMM1Q01'],fill_value=0,margins_name='tgtrtgr',margins = True)\n",
    "# potr =  potr.rename(columns={\"/BIC/ZMM1Q01\":\"_Потребность,кол-во\"})\n",
    "# potr = potr.set_index('gr_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potr_usd = ar[['gr_index','/BIC/ZMM1A01','CALYEAR','/BIC/ZMODUL']].pivot_table(index=['gr_index'],aggfunc='sum',columns=['CALYEAR','/BIC/ZMODUL'],values = ['/BIC/ZMM1A01'],fill_value=0,margins_name='tgtrtgr',margins = True)\n",
    "#     potr_usd =  potr_usd.rename(columns={\"/BIC/ZMM1A01\":\"_Потребность,стоимость,USD\"})\n",
    "#     potr_usd = potr_usd.set_index('gr_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[('ttt',x[1]) for x in potr_usd.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potr_usd.columns = pd.MultiIndex.from_tuples([('ttt',x[1]) for x in potr_usd.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potr_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([potr,potr_usd],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiindex(cols,ins_value):\n",
    "    arr = []\n",
    "    if len(cols)>1:\n",
    "        for el in cols:\n",
    "            a = list(el)\n",
    "            a[0] = ins_value\n",
    "            a = tuple(a)\n",
    "            arr.append(a)\n",
    "        return pd.MultiIndex.from_tuples(arr)\n",
    "    if len(cols)==1:\n",
    "        return [ins_value]\n",
    "\n",
    "def get_df_pvt_pandas(df,index_,columns_):\n",
    "    \n",
    "    index_join_group = copy.copy(index_) \n",
    "\n",
    "    vl06_index_join_group_start = copy.copy(index_join_group)\n",
    "    vl06_index_join_group_start.append('ZKFGDOCIN')\n",
    "\n",
    "\n",
    "\n",
    "    print(index_join_group)\n",
    "    \n",
    "    df['gr_index']=''\n",
    "    for ind, col in enumerate(index_join_group):\n",
    "        if ind==len(index_join_group)-1:\n",
    "            df['gr_index'] = df['gr_index'].astype('str')+df[col].astype('str')\n",
    "        else:\n",
    "            df['gr_index'] = df['gr_index'].astype('str')+df[col].astype('str')+'----'\n",
    "\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','/BIC/ZMM1Q01']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    potr = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['/BIC/ZMM1Q01'],fill_value=0,margins_name='_Потребность,кол-во',margins = True)\n",
    "    potr.columns = get_multiindex(potr.columns,'_Потребность,кол-во')\n",
    "    potr = potr[:-1]\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','/BIC/ZMM1A01']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    potr_usd = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['/BIC/ZMM1A01'],fill_value=0,margins_name='_Потребность,стоимость,USD',margins = True)\n",
    "    potr_usd.columns = get_multiindex(potr_usd.columns,'_Потребность,стоимость,USD')\n",
    "    potr_usd = potr_usd[:-1]\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','/BIC/ZMM1Q22']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    ost_raspr = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['/BIC/ZMM1Q22'],fill_value=0,margins_name='Распределение остатка,кол-во',margins = True)\n",
    "    ost_raspr.columns = get_multiindex(ost_raspr.columns,'Распределение остатка,кол-во')\n",
    "    ost_raspr = ost_raspr[:-1]\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','VALST_KZT']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    ost_raspr_KZT = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['VALST_KZT'],fill_value=0,margins_name='Сумма распределенного остатка,KZT',margins = True)\n",
    "    ost_raspr_KZT.columns = get_multiindex(ost_raspr_KZT.columns,'Сумма распределенного остатка,KZT')\n",
    "    ost_raspr_KZT = ost_raspr_KZT[:-1]\n",
    "    \n",
    "    gr = ['gr_index','VALST_USD']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    ost_raspr_USD = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['VALST_USD'],fill_value=0,margins_name='Сумма распределенного остатка,USD',margins = True)\n",
    "    ost_raspr_USD.columns = get_multiindex(ost_raspr_USD.columns,'Сумма распределенного остатка,USD')\n",
    "    ost_raspr_USD = ost_raspr_USD[:-1]\n",
    "    \n",
    "    gr = ['gr_index','ZKFGDOCIN']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    vl_06 = df[df['DOCTYPE'].isin(['VL06'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGDOCIN'],fill_value=0,margins_name='Товар в пути(VL06),кол-во',margins = True)\n",
    "    vl_06.columns = get_multiindex(vl_06.columns,'Товар в пути(VL06),кол-во')\n",
    "    vl_06 = vl_06[:-1]\n",
    "    \n",
    "    \n",
    "    znb_5 = df[df['DOCTYPE'].isin(['ZNB5'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGDOCIN'],fill_value=0,margins_name='Товар в пути(ZNB5),кол-во',margins = True)\n",
    "    znb_5.columns = get_multiindex(znb_5.columns,'Товар в пути(ZNB5),кол-во')\n",
    "    znb_5 = znb_5[:-1]\n",
    "    \n",
    "    znb_2_3_4 = df[df['DOCTYPE'].isin(['ZNB2','ZNB3','ZNB4'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGDOCIN'],fill_value=0,margins_name='Законтрактовано(ZNB2-4-ПртПзк),кол-во',margins = True)\n",
    "    znb_2_3_4.columns = get_multiindex(znb_2_3_4.columns,'Законтрактовано(ZNB2-4-ПртПзк),кол-во')\n",
    "    znb_2_3_4 = znb_2_3_4[:-1]\n",
    "    \n",
    "    nb = df[df['DOCTYPE'].apply(lambda x: len(re.findall('^NB\\d\\d',str(x)))>0 )][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGDOCIN'],fill_value=0,margins_name='Заявка на закуп(NB),кол-во',margins = True)\n",
    "    nb.columns = get_multiindex(nb.columns,'Заявка на закуп(NB),кол-во')\n",
    "    nb = nb[:-1]\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','ZKFGOUT']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    r_rash = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGOUT'],fill_value=0,margins_name='Распределение расхода, кол-во',margins = True)\n",
    "    r_rash.columns = get_multiindex(r_rash.columns,'Распределение расхода, кол-во')\n",
    "    r_rash = r_rash[:-1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    dfr = pd.concat([potr,potr_usd,ost_raspr,ost_raspr_KZT,ost_raspr_USD,vl_06,znb_5,znb_2_3_4,nb,r_rash],axis = 1)\n",
    "    \n",
    "    dfr = dfr.reset_index()\n",
    "    \n",
    "    for ind,col in enumerate(index_join_group):\n",
    "        dfr[col] = dfr['index'].apply(lambda x: str(x).split('----')[ind])\n",
    "    dfr = dfr.drop(['index'],axis = 1)\n",
    "    \n",
    "    for col in dfr.columns:\n",
    "        if dfr[col].dtype=='float64':\n",
    "            dfr[col].fillna(0,inplace = True)\n",
    "            \n",
    "#     if columns_==None:\n",
    "        \n",
    "# #         dfr.columns = [x[0] for x in dfr.columns]\n",
    "#         print(dfr.columns)\n",
    "    return dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    tt1  = get_df_pvt_pandas(df = ar,index_ = ['COMP_CODE','/BIC/ZNPLANT'],columns_=['CALYEAR','/BIC/ZMODUL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt1.to_excel(directory+'open_hub_.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = pd.concat([ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar,ar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potr_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potr_usd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiindex(cols):\n",
    "    arr = []\n",
    "    for el in potr_usd.columns:\n",
    "        a = list(el)\n",
    "        a[0] = 'hrth'\n",
    "        a = tuple(a)\n",
    "        arr.append(a)\n",
    "    return pd.MultiIndex.from_tuples(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.MultiIndex.from_tuples(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  =['f','t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0] = 'ddd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import dask\n",
    "import pandas as pd\n",
    "import re\n",
    "import zipfile\n",
    "import py7zr\n",
    "\n",
    "def get_arr_from_csv(dir_and_filename):\n",
    "    arr = []\n",
    "    with open(dir_and_filename) as File:\n",
    "        reader = csv.reader(File, delimiter=';', quotechar=',',\n",
    "                            quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in reader:\n",
    "            arr.append(row)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def get_dask_arr(directory,file_data_name,file_meta_name,types_pnds,cols_all):\n",
    "    arr_mtd = get_arr_from_csv(directory+file_meta_name+'.CSV')\n",
    "    arr_data = get_arr_from_csv(directory+file_data_name+'.CSV')\n",
    "    dict_meta = dict((x[0].strip(),x[1].strip()) for x in arr_mtd if len(x)>3 and x[0]!='COLUMN')\n",
    "    dict_meta_types = dict((x[0].strip(),x[3].strip()) for x in arr_mtd if len(x)>3 and x[0]!='COLUMN')\n",
    "    dfr = pd.DataFrame(data = arr_data,columns = list(dict_meta.values()))\n",
    "    \n",
    "    index_els = {}\n",
    "    a = 1\n",
    "    for el_0 in cols_all:\n",
    "        for ind, el in  enumerate(dfr.columns):\n",
    "            if el==el_0:\n",
    "                index_els[str(a)] =ind+1 \n",
    "                a+=1\n",
    "    \n",
    "        \n",
    "    \n",
    "    dfr = dfr[cols_all]\n",
    "    for ind,col in enumerate(dfr.columns,1):\n",
    "        \n",
    "        if types_pnds[dict_meta_types[str(index_els[str(ind)])]]=='float64':\n",
    "            \n",
    "            dfr[col] = dfr[col].apply(lambda x:x[-1]+x[:-1] if len(re.findall(r'-$',x))>0 else x)\n",
    "        dfr[col] = dfr[col].astype(types_pnds[dict_meta_types[str(index_els[str(ind)])]])\n",
    "    \n",
    "    sd = dfr\n",
    "    return sd\n",
    "\n",
    "\n",
    "def get_multiindex(cols,ins_value):\n",
    "    arr = []\n",
    "    if len(cols)>1:\n",
    "        for el in cols:\n",
    "            a = list(el)\n",
    "            a[0] = ins_value\n",
    "            a = tuple(a)\n",
    "            arr.append(a)\n",
    "        return pd.MultiIndex.from_tuples(arr)\n",
    "    if len(cols)==1:\n",
    "        return [ins_value]\n",
    "\n",
    "def get_df_pvt_pandas(df,index_,columns_):\n",
    "    index_join_group = copy.copy(index_) \n",
    "\n",
    "    vl06_index_join_group_start = copy.copy(index_join_group)\n",
    "    vl06_index_join_group_start.append('ZKFGDOCIN')\n",
    "\n",
    "\n",
    "\n",
    "#     print(index_join_group)\n",
    "    \n",
    "    df['gr_index']=''\n",
    "    for ind, col in enumerate(index_join_group):\n",
    "        if ind==len(index_join_group)-1:\n",
    "            df['gr_index'] = df['gr_index'].astype('str')+df[col].astype('str')\n",
    "        else:\n",
    "            df['gr_index'] = df['gr_index'].astype('str')+df[col].astype('str')+'----'\n",
    "\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','/BIC/ZMM1Q01']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    potr = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['/BIC/ZMM1Q01'],fill_value=0,margins_name='_Потребность,кол-во',margins = True)\n",
    "    potr.columns = get_multiindex(potr.columns,'_Потребность,кол-во')\n",
    "    potr = potr[:-1]\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','/BIC/ZMM1A01']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    potr_usd = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['/BIC/ZMM1A01'],fill_value=0,margins_name='_Потребность,стоимость,USD',margins = True)\n",
    "    potr_usd.columns = get_multiindex(potr_usd.columns,'_Потребность,стоимость,USD')\n",
    "    potr_usd = potr_usd[:-1]\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','/BIC/ZMM1Q22']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    ost_raspr = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['/BIC/ZMM1Q22'],fill_value=0,margins_name='Распределение остатка,кол-во',margins = True)\n",
    "    ost_raspr.columns = get_multiindex(ost_raspr.columns,'Распределение остатка,кол-во')\n",
    "    ost_raspr = ost_raspr[:-1]\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','VALST_KZT']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    ost_raspr_KZT = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['VALST_KZT'],fill_value=0,margins_name='Сумма распределенного остатка,KZT',margins = True)\n",
    "    ost_raspr_KZT.columns = get_multiindex(ost_raspr_KZT.columns,'Сумма распределенного остатка,KZT')\n",
    "    ost_raspr_KZT = ost_raspr_KZT[:-1]\n",
    "    \n",
    "    gr = ['gr_index','VALST_USD']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    ost_raspr_USD = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['VALST_USD'],fill_value=0,margins_name='Сумма распределенного остатка,USD',margins = True)\n",
    "    ost_raspr_USD.columns = get_multiindex(ost_raspr_USD.columns,'Сумма распределенного остатка,USD')\n",
    "    ost_raspr_USD = ost_raspr_USD[:-1]\n",
    "    \n",
    "    gr = ['gr_index','ZKFGDOCIN']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    vl_06 = df[df['DOCTYPE'].isin(['VL06'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGDOCIN'],fill_value=0,margins_name='Товар в пути(VL06),кол-во',margins = True)\n",
    "    vl_06.columns = get_multiindex(vl_06.columns,'Товар в пути(VL06),кол-во')\n",
    "    vl_06 = vl_06[:-1]\n",
    "    \n",
    "    \n",
    "    znb_5 = df[df['DOCTYPE'].isin(['ZNB5'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGDOCIN'],fill_value=0,margins_name='Товар в пути(ZNB5),кол-во',margins = True)\n",
    "    znb_5.columns = get_multiindex(znb_5.columns,'Товар в пути(ZNB5),кол-во')\n",
    "    znb_5 = znb_5[:-1]\n",
    "    \n",
    "    znb_2_3_4 = df[df['DOCTYPE'].isin(['ZNB2','ZNB3','ZNB4'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGDOCIN'],fill_value=0,margins_name='Законтрактовано(ZNB2-4-ПртПзк),кол-во',margins = True)\n",
    "    znb_2_3_4.columns = get_multiindex(znb_2_3_4.columns,'Законтрактовано(ZNB2-4-ПртПзк),кол-во')\n",
    "    znb_2_3_4 = znb_2_3_4[:-1]\n",
    "    \n",
    "    nb = df[df['DOCTYPE'].apply(lambda x: len(re.findall('^NB\\d\\d',str(x)))>0 )][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGDOCIN'],fill_value=0,margins_name='Заявка на закуп(NB),кол-во',margins = True)\n",
    "    nb.columns = get_multiindex(nb.columns,'Заявка на закуп(NB),кол-во')\n",
    "    nb = nb[:-1]\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','ZKFGOUT']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    r_rash = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGOUT'],fill_value=0,margins_name='Распределение расхода, кол-во',margins = True)\n",
    "    r_rash.columns = get_multiindex(r_rash.columns,'Распределение расхода, кол-во')\n",
    "    r_rash = r_rash[:-1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    dfr = pd.concat([potr,potr_usd,ost_raspr,ost_raspr_KZT,ost_raspr_USD,vl_06,znb_5,znb_2_3_4,nb,r_rash],axis = 1)\n",
    "    \n",
    "    dfr = dfr.reset_index()\n",
    "    \n",
    "    for ind,col in enumerate(index_join_group):\n",
    "        dfr[col] = dfr['index'].apply(lambda x: str(x).split('----')[ind])\n",
    "    dfr = dfr.drop(['index'],axis = 1)\n",
    "    \n",
    "    for col in dfr.columns:\n",
    "        if dfr[col].dtype=='float64':\n",
    "            dfr[col].fillna(0,inplace = True)\n",
    "            \n",
    "#     if columns_==None:\n",
    "        \n",
    "# #         dfr.columns = [x[0] for x in dfr.columns]\n",
    "#         print(dfr.columns)\n",
    "    return dfr\n",
    "\n",
    "# arr = []\n",
    "# # directory = 'C:\\\\Users\\\\NKedrun\\\\AppData\\\\Local\\\\VirtualStore\\\\'\n",
    "# directory = '\\\\\\\\kzukgs2sapf0.kazzinc.kz\\\\uz_reports_KIP\\\\test\\\\'\n",
    "# types_pnds = {'CHAR':'category','CUKY':'category','CURR':'float64','FLTP':'float64','NUMC':'category','QUAN':'float64','UNIT':'category','DATS':'category'}\n",
    "\n",
    "# ar = get_dask_arr(directory,'ZPR1OH01','S_ZPR1OH01')\n",
    "\n",
    "# tt1  = get_df_pvt_pandas(df = ar,index_ = ['/BIC/ZNDOCTYPE'],columns_=None)\n",
    "\n",
    "# tt2  = get_df_pvt_pandas(df = ar,index_ = ['CALYEAR'],columns_=None)\n",
    "\n",
    "\n",
    "def get_report(years,months,directory_temp,directory_zip,index_,columns_):\n",
    "    arr_cons = []\n",
    "    types_pnds = {'CHAR':'category','CUKY':'category','CURR':'float64','FLTP':'float64','NUMC':'category','QUAN':'float64','UNIT':'category','DATS':'category'}\n",
    "    cols_all = ['/BIC/ZMM1Q01','/BIC/ZMM1A01','/BIC/ZMM1Q22','VALST_KZT','VALST_USD','ZKFGDOCIN','DOCTYPE','ZKFGOUT']\n",
    "    cols_all.extend(index_)\n",
    "    if columns_ is not  None:\n",
    "        cols_all.extend(columns_)\n",
    "    \n",
    "    for year in years:\n",
    "        for month in months:\n",
    "#             z = zipfile.ZipFile(directory_zip+str(year)+'\\\\'+str(month)+'\\\\VirtualStore.zip', 'r')\n",
    "#             z.extractall(directory_temp)\n",
    "            z = py7zr.SevenZipFile(directory_zip+str(year)+'\\\\'+str(month)+'\\\\VirtualStore.7z', mode='r')\n",
    "            z.extractall(path=directory_temp)\n",
    "            z.close()\n",
    "            ar = get_dask_arr(directory_temp,'ZPR1OH01','S_ZPR1OH01',types_pnds,cols_all)\n",
    "            arr_cons.append(ar)\n",
    "            print('Загрузил '+str(year)+' '+str(month))\n",
    "            \n",
    "            \n",
    "    cons = pd.concat(arr_cons)\n",
    "    tt1  = get_df_pvt_pandas(df = cons,index_ = index_,columns_=columns_)\n",
    "    \n",
    "    return tt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory_temp = 'C:\\\\Users\\\\NKedrun\\\\Desktop\\\\temp\\\\'\n",
    "# directory_zip = 'C:\\\\Users\\\\NKedrun\\\\Desktop\\\\test\\\\'\n",
    "directory_zip = '\\\\\\\\kzukgs2sapf0.kazzinc.kz\\\\uz_reports_KIP\\\\test\\\\'\n",
    "index_ = ['MATERIAL','DATE0']\n",
    "columns_ = ['/BIC/ZSTOCKCAT']\n",
    "years = [2020]\n",
    "months = [3,8,9]\n",
    "\n",
    "\n",
    "df = get_report(years = years,months = months,index_ = index_,columns_ = columns_,directory_temp=directory_temp,directory_zip=directory_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.extractall('C:\\\\Users\\\\NKedrun\\\\Desktop\\\\temp\\\\')\n",
    "z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'NKEDRUN'\n",
    "passwd = 'F292twmmwt292f!!!'\n",
    "saprouter = 'kzukgs8bwop0.kazzinc.kz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Connection(user=user, passwd=passwd,\n",
    "                  mshost='CLient',\n",
    "                  msserv='kzukgs8bwop0',\n",
    "                  sysid='KIP',\n",
    "                  group=\"PUBLIC\",\n",
    "                  saprouter=saprouter, \n",
    "                  client='500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrfc import Connection\n",
    "ASHOST='kzukgs8bwop1'\n",
    "CLIENT='500'\n",
    "SYSNR='KIP'\n",
    "USER='NKEDRUN'\n",
    "PASSWD='F292twmmwt292f!!!'\n",
    "conn = Connection(ashost=ASHOST, sysnr=SYSNR, client=CLIENT, user=USER, passwd=PASSWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_result = conn.call('BAPI_USER_GET_DETAIL',\n",
    "                     USERNAME = 'user',\n",
    "                     CACHE_RESULTS  = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [{ 'TEXT': \"FCURR = 'USD'\"}]\n",
    "rowskips = 0\n",
    "ROWS_AT_A_TIME = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conn.call('RFC_READ_TABLE',QUERY_TABLE = 'TCURR', OPTIONS = options, ROWSKIPS = rowskips, ROWCOUNT = ROWS_AT_A_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.call('ZPR1VPR29',QUERY_TABLE = 'F1 - Документы пополнения')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.call('RFC_READ_TABLE',QUERY_TABLE = 'ZPR1VRP29_Q001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrfc import Connection\n",
    "ASHOST='kzukgs8bwboq0'\n",
    "CLIENT='300'\n",
    "SYSNR='KIQ'\n",
    "USER='TEST_MMREPOR'\n",
    "PASSWD='F292twmmwt292f!'\n",
    "conn = Connection(ashost=ASHOST, sysnr=SYSNR, client=CLIENT, user=USER, passwd=PASSWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.call('RFC_READ_TABLE',QUERY_TABLE = 'ZKAZ/ZKAZ_PR1/ZKAZ_PR1_VR/ZPR1VRP26/ZPR1VRP26_Q001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.call('BAPI_USER_GET_DETAIL',\n",
    "                     USERNAME = 'TEST_MMREPOR',\n",
    "                     CACHE_RESULTS  = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrfc import Connection, ABAPApplicationError, ABAPRuntimeError, LogonError, CommunicationError\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "\n",
    "def main():\n",
    "\n",
    "    try:\n",
    "\n",
    "        ASHOST='kzukgs8bwboq0'\n",
    "        CLIENT='300'\n",
    "        SYSNR='KIQ'\n",
    "        USER='TEST_MMREPOR'\n",
    "        PASSWD='F292twmmwt292f!'\n",
    "        conn = Connection(ashost=ASHOST, sysnr=SYSNR, client=CLIENT, user=USER, passwd=PASSWD)\n",
    "\n",
    "        options = [{ 'TEXT': \"FCURR = 'USD'\"}]\n",
    "        pp = PrettyPrinter(indent=4)\n",
    "        ROWS_AT_A_TIME = 10 \n",
    "        rowskips = 0\n",
    "\n",
    "        while True:\n",
    "            print (\"----Begin of Batch---\")\n",
    "            result = conn.call('RFC_READ_TABLE', \\\n",
    "                                QUERY_TABLE = 'TCURR', \\\n",
    "                                OPTIONS = options, \\\n",
    "                                ROWSKIPS = rowskips, ROWCOUNT = ROWS_AT_A_TIME)\n",
    "            pp.pprint(result['DATA'])\n",
    "            rowskips += ROWS_AT_A_TIME\n",
    "            if len(result['DATA']) < ROWS_AT_A_TIME:\n",
    "                break\n",
    "\n",
    "    except CommunicationError:\n",
    "        print (\"Could not connect to server.\")\n",
    "        raise\n",
    "    except LogonError:\n",
    "        print (\"Could not log in. Wrong credentials?\")\n",
    "        raise\n",
    "    except (ABAPApplicationError, ABAPRuntimeError):\n",
    "        print (\"An error occurred.\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrfc import Connection\n",
    "ASHOST='kzukgs8bwboq0'\n",
    "CLIENT='300'\n",
    "SYSNR='KIQ'\n",
    "USER='NKEDRUN'\n",
    "PASSWD='F292twmmwt292f!!!'\n",
    "conn = Connection(ashost=ASHOST, sysnr=SYSNR, client=CLIENT, user=USER, passwd=PASSWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = conn.call('RFC_READ_TABLE',QUERY_TABLE = \"/BIC/AZPR1DPA522\",DELIMITER='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['FIELDS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x  in result['DATA'][0]['WA'].split('|')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowskips = 0\n",
    "ROWS_AT_A_TIME = 1000\n",
    "fiels = ['CALYEAR','ZKFGOUT']\n",
    "result = conn.call('RFC_READ_TABLE',QUERY_TABLE = \"/BIC/AZPR1DPA572\",FIELDS = fiels,ROWSKIPS = rowskips, ROWCOUNT = ROWS_AT_A_TIME,DELIMITER='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "rowskips = 0\n",
    "ROWS_AT_A_TIME = 300000\n",
    "fiels = ['CALYEAR','PLANT','VENDOR','MATERIAL']\n",
    "options = [{ 'TEXT': \"Z0DATE_MSMR_01 = 2020/10/1\"}]\n",
    "while True:\n",
    "    result = conn.call('RFC_READ_TABLE',\\\n",
    "                       QUERY_TABLE = \"/BIC/AZPR1DPA542\",\\\n",
    "                       FIELDS = fiels,\\\n",
    "                       ROWSKIPS = rowskips, \\\n",
    "                       ROWCOUNT = ROWS_AT_A_TIME,DELIMITER='|',OPTIONS = options)\n",
    "    \n",
    "    for x in [x['WA'].split('|') for x  in  result['DATA']]:\n",
    "        lst.append(x)\n",
    "        \n",
    "    rowskips += ROWS_AT_A_TIME  \n",
    "    \n",
    "    print(str(len(lst))+'_'+str(rowskips))     \n",
    "    if len(result['DATA']) < ROWS_AT_A_TIME:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py7zr\n",
    "archive = py7zr.SevenZipFile('C:\\\\Users\\\\NKedrun\\\\Desktop\\\\temp\\\\temp.7z', mode='r')\n",
    "archive.extractall(path=\"C:\\\\Users\\\\NKedrun\\\\Desktop\\\\test\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_arr_from_csv(dir_and_filename):\n",
    "    arr = []\n",
    "    with open(dir_and_filename,encoding='utf-8') as File:\n",
    "        reader = csv.reader(File, delimiter=';', quotechar=',',\n",
    "                            quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in reader:\n",
    "            arr.append(row)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def get_dask_arr(directory,file_data_name,file_meta_name,types_pnds,cols_all):\n",
    "    arr_mtd = get_arr_from_csv(directory+file_meta_name+'.CSV')\n",
    "    arr_data = get_arr_from_csv(directory+file_data_name+'.CSV')\n",
    "    dict_meta = dict((x[0].strip(),x[1].strip()) for x in arr_mtd if len(x)>3 and x[0]!='COLUMN')\n",
    "    dict_meta_types = dict((x[0].strip(),x[3].strip()) for x in arr_mtd if len(x)>3 and x[0]!='COLUMN')\n",
    "    dfr = pd.DataFrame(data = arr_data,columns = list(dict_meta.values()))\n",
    "    \n",
    "    index_els = {}\n",
    "    a = 1\n",
    "    for el_0 in cols_all:\n",
    "        for ind, el in  enumerate(dfr.columns):\n",
    "            if el==el_0:\n",
    "                index_els[str(a)] =ind+1 \n",
    "                a+=1\n",
    "    \n",
    "        \n",
    "    \n",
    "    dfr = dfr[cols_all]\n",
    "    for ind,col in enumerate(dfr.columns,1):\n",
    "        \n",
    "        if types_pnds[dict_meta_types[str(index_els[str(ind)])]]=='float64':\n",
    "            \n",
    "            dfr[col] = dfr[col].apply(lambda x:x[-1]+x[:-1] if len(re.findall(r'-$',x))>0 else x)\n",
    "        dfr[col] = dfr[col].astype(types_pnds[dict_meta_types[str(index_els[str(ind)])]])\n",
    "    \n",
    "    sd = dfr\n",
    "    return sd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_report(years,months,directory_temp,directory_zip,index_,columns_):\n",
    "    arr_cons = []\n",
    "    types_pnds = {'CHAR':'category','CUKY':'category','CURR':'float64','FLTP':'float64','NUMC':'category','QUAN':'float64','UNIT':'category','DATS':'category'}\n",
    "    cols_all = ['/BIC/ZMM1Q01','/BIC/ZMM1A01','/BIC/ZMM1Q22','VALST_KZT','VALST_USD','ZKFGDOCIN','DOCTYPE','ZKFGOUT']\n",
    "    cols_all.extend(index_)\n",
    "    if columns_ is not  None:\n",
    "        cols_all.extend(columns_)\n",
    "    \n",
    "  \n",
    "    ar = get_dask_arr(directory_temp,'F1_EXTRACTION_2021_04_07','S_F1_EXTRACTION_2021_04_07',types_pnds,cols_all)\n",
    "    arr_cons.append(ar)\n",
    "\n",
    "            \n",
    "            \n",
    "    cons = pd.concat(arr_cons)\n",
    "    return cons\n",
    "#     tt1  = get_df_pvt_pandas(df = cons,index_ = index_,columns_=columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_temp = 'C:\\\\Users\\\\NKedrun\\\\Desktop\\\\openHub_arr\\\\'\n",
    "# directory_zip = 'C:\\\\Users\\\\NKedrun\\\\Desktop\\\\test\\\\'\n",
    "directory_zip = 'C:\\\\Users\\\\NKedrun\\\\Desktop\\\\VirtualStore\\\\'\n",
    "index_ = ['MATERIAL','DATE0']\n",
    "columns_ = ['/BIC/ZSTOCKCAT']\n",
    "years = [2020]\n",
    "months = [3,8,9]\n",
    "\n",
    "\n",
    "df = get_report(years = years,months = months,index_ = index_,columns_ = columns_,directory_temp=directory_temp,directory_zip=directory_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATE0'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt1  = get_df_pvt_pandas(df = df,index_ = index_,columns_=columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt12 = tt1[tt1['DATE0']=='20210218']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt12.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt12['Сумма распределенного остатка,KZT']['Сумма распределенного остатка,KZT'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['DATE0']=='00000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = 'C:\\\\Users\\\\NKedrun\\\\Desktop\\\\openHub_arr\\\\F1_EXTRACTION_2021_04_07.csv'\n",
    "chunksize = 500000 \n",
    "\n",
    "cols = list(traintypes.keys())\n",
    "\n",
    "df_list = [] # list to hold the batch dataframe\n",
    "\n",
    "for df_chunk in tqdm(pd.read_csv(PATH, chunksize=chunksize,delimiter=';', quotechar=',')):\n",
    "    # Can process each chunk of dataframe here\n",
    "    # clean_data(), feature_engineer(),fit()\n",
    "\n",
    "    # Alternatively, append the chunk to list and merge all\n",
    "    df_list.append(df_chunk) \n",
    "\n",
    "# Merge all dataframes into one dataframe\n",
    "X = pd.concat(df_list)\n",
    "\n",
    "# Delete the dataframe list to release memory\n",
    "del df_list\n",
    "del df_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "pd.set_option('display.max_columns', None)\n",
    "from pyexcelerate import Workbook\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import csv\n",
    "import copy\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_multiindex(cols,ins_value):\n",
    "    arr = []\n",
    "    if len(cols)>1:\n",
    "        for el in cols:\n",
    "            a = list(el)\n",
    "            a[0] = ins_value\n",
    "            a = tuple(a)\n",
    "            arr.append(a)\n",
    "        return pd.MultiIndex.from_tuples(arr)\n",
    "    if len(cols)==1:\n",
    "        return [ins_value]\n",
    "\n",
    "\n",
    "def get_df_pvt_pandas(df,index_,columns_,filters_):\n",
    "    index_join_group = copy.copy(index_) \n",
    "\n",
    "    vl06_index_join_group_start = copy.copy(index_join_group)\n",
    "    vl06_index_join_group_start.append('ZKFGDOCIN')\n",
    "    \n",
    "    getTrFalse = df.isin(filters_)\n",
    "    arr =  np.array(getTrFalse)\n",
    "    index_ = getTrFalse[np.sum(arr,axis = 1)==len(filters.keys())].index\n",
    "    df = df.loc[index_]\n",
    "    if len(df)==0:\n",
    "        print('Данных по данному фильтру нет')\n",
    "        return \n",
    "#     df = df[df[list(filters_.keys())[0]].isin(filters_[list(filters_.keys())[0]])]\n",
    "\n",
    "#     print(index_join_group)\n",
    "    \n",
    "    df['gr_index']=''\n",
    "    for ind, col in enumerate(index_join_group):\n",
    "        if ind==len(index_join_group)-1:\n",
    "            df['gr_index'] = df['gr_index'].astype('str')+df[col].astype('str')\n",
    "        else:\n",
    "            df['gr_index'] = df['gr_index'].astype('str')+df[col].astype('str')+'----'\n",
    "\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','/BIC/ZMM1Q01']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    potr = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['/BIC/ZMM1Q01'],fill_value=0,margins_name='_Потребность,кол-во',margins = True)\n",
    "    potr.columns = get_multiindex(potr.columns,'_Потребность,кол-во')\n",
    "    potr = potr[:-1]\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','/BIC/ZMM1A01']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    potr_usd = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['/BIC/ZMM1A01'],fill_value=0,margins_name='_Потребность,стоимость,USD',margins = True)\n",
    "    potr_usd.columns = get_multiindex(potr_usd.columns,'_Потребность,стоимость,USD')\n",
    "    potr_usd = potr_usd[:-1]\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','/BIC/ZMM1Q22']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    ost_raspr = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['/BIC/ZMM1Q22'],fill_value=0,margins_name='Распределение остатка,кол-во',margins = True)\n",
    "    ost_raspr.columns = get_multiindex(ost_raspr.columns,'Распределение остатка,кол-во')\n",
    "    ost_raspr = ost_raspr[:-1]\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','VALST_KZT']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    ost_raspr_KZT = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['VALST_KZT'],fill_value=0,margins_name='Сумма распределенного остатка,KZT',margins = True)\n",
    "    ost_raspr_KZT.columns = get_multiindex(ost_raspr_KZT.columns,'Сумма распределенного остатка,KZT')\n",
    "    ost_raspr_KZT = ost_raspr_KZT[:-1]\n",
    "    \n",
    "    gr = ['gr_index','VALST_USD']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    ost_raspr_USD = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['VALST_USD'],fill_value=0,margins_name='Сумма распределенного остатка,USD',margins = True)\n",
    "    ost_raspr_USD.columns = get_multiindex(ost_raspr_USD.columns,'Сумма распределенного остатка,USD')\n",
    "    ost_raspr_USD = ost_raspr_USD[:-1]\n",
    "    \n",
    "    gr = ['gr_index','ZKFGDOCIN']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "        \n",
    "        \n",
    "    if df[df['DOCTYPE'].isin(['VL06'])].shape[0]>0:    \n",
    "        vl_06 = df[df['DOCTYPE'].isin(['VL06'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGDOCIN'],fill_value=0,margins_name='Товар в пути(VL06),кол-во',margins = True)\n",
    "        vl_06.columns = get_multiindex(vl_06.columns,'Товар в пути(VL06),кол-во')        \n",
    "        vl_06 = vl_06[:-1]\n",
    "    else:\n",
    "        vl_06 = pd.DataFrame(columns=[('Товар в пути(VL06),кол-во', 'Данных нет')])\n",
    "        vl_06.columns = pd.MultiIndex.from_tuples([('Товар в пути(VL06),кол-во', 'Данных нет')]) \n",
    "        vl_06 = vl_06[:-1]\n",
    "            \n",
    "    \n",
    "    if df[df['DOCTYPE'].isin(['ZNB5'])].shape[0]>0:\n",
    "        znb_5 = df[df['DOCTYPE'].isin(['ZNB5'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGDOCIN'],fill_value=0,margins_name='Товар в пути(ZNB5),кол-во',margins = True)\n",
    "        znb_5.columns = get_multiindex(znb_5.columns,'Товар в пути(ZNB5),кол-во')\n",
    "        znb_5 = znb_5[:-1]\n",
    "    else:\n",
    "\n",
    "        znb_5 = pd.DataFrame(columns=[('Товар в пути(ZNB5),кол-во', 'Данных нет')])\n",
    "        znb_5.columns = pd.MultiIndex.from_tuples([('Товар в пути(ZNB5),кол-во', 'Данных нет')]) \n",
    "        znb_5 = znb_5[:-1]\n",
    "    \n",
    "    \n",
    "    if df[df['DOCTYPE'].isin(['ZNB2','ZNB3','ZNB4'])].shape[0]>0:\n",
    "        znb_2_3_4 = df[df['DOCTYPE'].isin(['ZNB2','ZNB3','ZNB4'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGDOCIN'],fill_value=0,margins_name='Законтрактовано(ZNB2-4-ПртПзк),кол-во',margins = True)\n",
    "        znb_2_3_4.columns = get_multiindex(znb_2_3_4.columns,'Законтрактовано(ZNB2-4-ПртПзк),кол-во')\n",
    "        znb_2_3_4 = znb_2_3_4[:-1]\n",
    "    else:\n",
    "        znb_2_3_4 = pd.DataFrame(columns=[('Законтрактовано(ZNB2-4-ПртПзк),кол-во', 'Данных нет')])\n",
    "        znb_2_3_4.columns = pd.MultiIndex.from_tuples([('Законтрактовано(ZNB2-4-ПртПзк),кол-во', 'Данных нет')]) \n",
    "        znb_2_3_4 = znb_2_3_4[:-1]\n",
    "    \n",
    "    nb = df[df['DOCTYPE'].apply(lambda x: len(re.findall('^NB\\d\\d',str(x)))>0 )][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGDOCIN'],fill_value=0,margins_name='Заявка на закуп(NB),кол-во',margins = True)\n",
    "    nb.columns = get_multiindex(nb.columns,'Заявка на закуп(NB),кол-во')\n",
    "    nb = nb[:-1]\n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','ZKFGOUT']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    r_rash = df[gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGOUT'],fill_value=0,margins_name='Распределение расхода, кол-во',margins = True)\n",
    "    r_rash.columns = get_multiindex(r_rash.columns,'Распределение расхода, кол-во')\n",
    "    r_rash = r_rash[:-1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','ZKFGIN']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "        \n",
    "    if df[df['/BIC/ZDECADE'].isin([1])].shape[0]>0:    \n",
    "        r_prih_1 = df[df['/BIC/ZDECADE'].isin([1])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGIN'],fill_value=0,margins_name='Распределение прихода 1декада, кол-во',margins = True)\n",
    "        r_prih_1.columns = get_multiindex(r_prih_1.columns,'Распределение прихода 1декада, кол-во')\n",
    "        r_prih_1 = r_prih_1[:-1]\n",
    "    else:\n",
    "        r_prih_1 = pd.DataFrame(columns=[('Распределение прихода 1декада, кол-во', 'Данных нет')])\n",
    "        r_prih_1.columns = pd.MultiIndex.from_tuples([('Распределение прихода 1декада, кол-во', 'Данных нет')]) \n",
    "        r_prih_1 = r_prih_1[:-1]\n",
    "        \n",
    "        \n",
    "    \n",
    "    if df[df['/BIC/ZDECADE'].isin([2])].shape[0]>0:    \n",
    "        r_prih_2 = df[df['/BIC/ZDECADE'].isin([2])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGIN'],fill_value=0,margins_name='Распределение прихода 2декада, кол-во',margins = True)\n",
    "        r_prih_2.columns = get_multiindex(r_prih_2.columns,'Распределение прихода 2декада, кол-во')\n",
    "        r_prih_2 = r_prih_2[:-1]\n",
    "    else:\n",
    "        r_prih_2 = pd.DataFrame(columns=[('Распределение прихода 2декада, кол-во', 'Данных нет')])\n",
    "        r_prih_2.columns = pd.MultiIndex.from_tuples([('Распределение прихода 2декада, кол-во', 'Данных нет')]) \n",
    "        r_prih_2 = r_prih_2[:-1]\n",
    "        \n",
    "        \n",
    "        \n",
    "    if df[df['/BIC/ZDECADE'].isin([3])].shape[0]>0:    \n",
    "        r_prih_3 = df[df['/BIC/ZDECADE'].isin([3])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['ZKFGIN'],fill_value=0,margins_name='Распределение прихода 3декада, кол-во',margins = True)\n",
    "        r_prih_3.columns = get_multiindex(r_prih_2.columns,'Распределение прихода 3декада, кол-во')\n",
    "        r_prih_3 = r_prih_3[:-1]\n",
    "    else:\n",
    "        r_prih_3 = pd.DataFrame(columns=[('Распределение прихода 3декада, кол-во', 'Данных нет')])\n",
    "        r_prih_3.columns = pd.MultiIndex.from_tuples([('Распределение прихода 3декада, кол-во', 'Данных нет')]) \n",
    "        r_prih_3 = r_prih_3[:-1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    gr = ['gr_index','/BIC/ZCPPVCC']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if df[df['FLAG_DISTR'].isin(['I','N','P','T'])].shape[0]>0:    \n",
    "        r_prih_sum = df[df['FLAG_DISTR'].isin(['I','N','P','T'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['/BIC/ZCPPVCC'],fill_value=0,margins_name='Сумма распределенного прихода, USD',margins = True)\n",
    "        r_prih_sum.columns = get_multiindex(r_prih_sum.columns,'Сумма распределенного прихода, USD')\n",
    "        r_prih_sum = r_prih_sum[:-1]\n",
    "    else:\n",
    "        r_prih_sum = pd.DataFrame(columns=[('Сумма распределенного прихода, USD', 'Данных нет')])\n",
    "        r_prih_sum.columns = pd.MultiIndex.from_tuples([('Сумма распределенного прихода, USD', 'Данных нет')]) \n",
    "        r_prih_sum = r_prih_sum[:-1]\n",
    "        \n",
    "        \n",
    "    if df[df['FLAG_DISTR'].isin(['U','O'])].shape[0]>0:    \n",
    "        r_rash_sum = df[df['FLAG_DISTR'].isin(['U','O'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['/BIC/ZCPPVCC'],fill_value=0,margins_name='Сумма распределенного расхода, USD',margins = True)\n",
    "        r_rash_sum.columns = get_multiindex(r_rash_sum.columns,'Сумма распределенного расхода, USD')\n",
    "        r_rash_sum = r_rash_sum[:-1]\n",
    "    else:\n",
    "        r_rash_sum = pd.DataFrame(columns=[('Сумма распределенного расхода, USD', 'Данных нет')])\n",
    "        r_rash_sum.columns = pd.MultiIndex.from_tuples([('Сумма распределенного расхода, USD', 'Данных нет')]) \n",
    "        r_rash_sum = r_rash_sum[:-1]\n",
    "\n",
    "        \n",
    "    gr = ['gr_index','CPPVLC']\n",
    "    if columns_!=None:\n",
    "        gr.extend(columns_)\n",
    "        \n",
    "        \n",
    "    if df[df['FLAG_DISTR'].isin(['I','N','P','T'])].shape[0]>0:    \n",
    "        r_prih_sum_KZT = df[df['FLAG_DISTR'].isin(['I','N','P','T'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['CPPVLC'],fill_value=0,margins_name='Сумма распределенного прихода, KZT',margins = True)\n",
    "        r_prih_sum_KZT.columns = get_multiindex(r_prih_sum_KZT.columns,'Сумма распределенного прихода, KZT')\n",
    "        r_prih_sum_KZT = r_prih_sum_KZT[:-1]\n",
    "#         print(r_prih_sum_KZT)\n",
    "    else:\n",
    "        r_prih_sum_KZT = pd.DataFrame(columns=[('Сумма распределенного прихода, KZT', 'Данных нет')])\n",
    "        r_prih_sum_KZT.columns = pd.MultiIndex.from_tuples([('Сумма распределенного прихода, KZT', 'Данных нет')]) \n",
    "        r_prih_sum_KZT = r_prih_sum_KZT[:-1]\n",
    "        \n",
    "        \n",
    "        \n",
    "    if df[df['FLAG_DISTR'].isin(['U','O'])].shape[0]>0:    \n",
    "        r_rash_sum_KZT = df[df['FLAG_DISTR'].isin(['U','O'])][gr].pivot_table(index=['gr_index'],aggfunc='sum',columns=columns_,values = ['CPPVLC'],fill_value=0,margins_name='Сумма распределенного расхода, KZT',margins = True)\n",
    "        r_rash_sum_KZT.columns = get_multiindex(r_rash_sum_KZT.columns,'Сумма распределенного расхода, KZT')\n",
    "        r_rash_sum_KZT = r_rash_sum_KZT[:-1]\n",
    "    else:\n",
    "        r_rash_sum_KZT = pd.DataFrame(columns=[('Сумма распределенного расхода, KZT', 'Данных нет')])\n",
    "        r_rash_sum_KZT.columns = pd.MultiIndex.from_tuples([('Сумма распределенного расхода, KZT', 'Данных нет')]) \n",
    "        r_rash_sum_KZT = r_rash_sum_KZT[:-1]\n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dfr = pd.concat([potr,potr_usd,ost_raspr,ost_raspr_KZT,ost_raspr_USD,vl_06,znb_5,znb_2_3_4,nb,r_rash,r_rash_sum,r_rash_sum_KZT,r_prih_1,r_prih_2,r_prih_3,r_prih_sum,r_prih_sum_KZT],axis = 1)\n",
    "    \n",
    "    dfr = dfr.reset_index()\n",
    "    \n",
    "    for ind,col in enumerate(index_join_group):\n",
    "        dfr[col] = dfr['index'].apply(lambda x: str(x).split('----')[ind])\n",
    "    dfr = dfr.drop(['index'],axis = 1)\n",
    "    \n",
    "    \n",
    "    for col in dfr.columns:\n",
    "#         print(type(dfr[col]))\n",
    "        if dfr[col].dtype=='float64':\n",
    "            dfr[col].fillna(0,inplace = True)\n",
    "            \n",
    "#     if columns_==None:\n",
    "        \n",
    "# #         dfr.columns = [x[0] for x in dfr.columns]\n",
    "#         print(dfr.columns)\n",
    "    return dfr\n",
    "\n",
    "# arr = []\n",
    "# # directory = 'C:\\\\Users\\\\NKedrun\\\\AppData\\\\Local\\\\VirtualStore\\\\'\n",
    "# directory = '\\\\\\\\kzukgs2sapf0.kazzinc.kz\\\\uz_reports_KIP\\\\test\\\\'\n",
    "# types_pnds = {'CHAR':'category','CUKY':'category','CURR':'float64','FLTP':'float64','NUMC':'category','QUAN':'float64','UNIT':'category','DATS':'category'}\n",
    "\n",
    "# ar = get_dask_arr(directory,'ZPR1OH01','S_ZPR1OH01')\n",
    "\n",
    "# tt1  = get_df_pvt_pandas(df = ar,index_ = ['/BIC/ZNDOCTYPE'],columns_=None)\n",
    "\n",
    "# tt2  = get_df_pvt_pandas(df = ar,index_ = ['CALYEAR'],columns_=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_arr_from_csv(dir_and_filename):\n",
    "    arr = []\n",
    "    with open(dir_and_filename,encoding='utf-8') as File:\n",
    "        reader = csv.reader(File, delimiter=';', quotechar=',',\n",
    "                            quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in reader:\n",
    "            arr.append(row)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_dask_arr(directory,file_data_name,file_meta_name,types_pnds,cols_all):\n",
    "    arr_mtd = get_arr_from_csv(directory+file_meta_name+'.CSV')\n",
    "#     arr_data = get_arr_from_csv(directory+file_data_name+'.CSV')\n",
    "    dict_meta = dict((x[0].strip(),x[1].strip()) for x in arr_mtd if len(x)>3 and x[0]!='COLUMN')\n",
    "    dict_meta_types = dict((x[0].strip(),x[3].strip()) for x in arr_mtd if len(x)>3 and x[0]!='COLUMN')\n",
    "    \n",
    "    chunksize = 1000000 \n",
    "\n",
    "\n",
    "    df_list = [] # list to hold the batch dataframe\n",
    "\n",
    "    for df_chunk in tqdm(pd.read_csv(directory+file_data_name+'.CSV',quoting=csv.QUOTE_MINIMAL,header=None, chunksize=chunksize,delimiter=';', quotechar=',')):\n",
    "        # Can process each chunk of dataframe here\n",
    "        # clean_data(), feature_engineer(),fit()\n",
    "\n",
    "        # Alternatively, append the chunk to list and merge all\n",
    "        df_list.append(df_chunk) \n",
    "\n",
    "    # Merge all dataframes into one dataframe\n",
    "    dfr = pd.concat(df_list)\n",
    "    dfr.columns = list(dict_meta.values())\n",
    "    # Delete the dataframe list to release memory\n",
    "    del df_list\n",
    "    del df_chunk\n",
    "    \n",
    "    print('Загрузили,начинаем обработку')\n",
    "    \n",
    "    index_els = {}\n",
    "    a = 1\n",
    "    for el_0 in cols_all:\n",
    "        for ind, el in  enumerate(dfr.columns):\n",
    "            if el==el_0:\n",
    "                index_els[str(a)] =ind+1 \n",
    "                a+=1\n",
    "    \n",
    "        \n",
    "    \n",
    "    dfr = dfr[cols_all]\n",
    "    for ind,col in enumerate(dfr.columns,1):\n",
    "        \n",
    "        if types_pnds[dict_meta_types[str(index_els[str(ind)])]]=='float64':\n",
    "            \n",
    "            dfr[col] = dfr[col].astype('str').apply(lambda x:x[-1]+x[:-1] if len(re.findall(r'-$',x))>0 else x)\n",
    "        dfr[col].fillna('',inplace = True)\n",
    "        dfr[col] = dfr[col].astype(types_pnds[dict_meta_types[str(index_els[str(ind)])]])\n",
    "    \n",
    "    sd = dfr\n",
    "#     sd = sd.fillna(0)\n",
    "    print('Загрузка данных завершена')\n",
    "    return sd\n",
    "\n",
    "\n",
    "def get_report(directory_temp,index_,columns_,filename,filename_meta):\n",
    "    arr_cons = []\n",
    "    types_pnds = {'CHAR':'category','CUKY':'category','CURR':'float64','FLTP':'float64','NUMC':'category','QUAN':'float64','UNIT':'category','DATS':'category'}\n",
    "    cols_all = ['/BIC/ZMM1Q01','/BIC/ZMM1A01','/BIC/ZMM1Q22','VALST_KZT','VALST_USD','ZKFGDOCIN','DOCTYPE','ZKFGOUT','/BIC/ZDECADE','FLAG_DISTR','/BIC/ZCPPVCC','ZKFGIN','CPPVLC']\n",
    "    cols_all.extend(index_)\n",
    "    if columns_ is not  None:\n",
    "        cols_all.extend(columns_)\n",
    "    \n",
    "  \n",
    "    ar = get_dask_arr(directory_temp,filename,filename_meta,types_pnds,cols_all)\n",
    "#     arr_cons.append(ar)\n",
    "\n",
    "            \n",
    "            \n",
    "#     cons = pd.concat(arr_cons)\n",
    "    return ar\n",
    "#     tt1  = get_df_pvt_pandas(df = cons,index_ = index_,columns_=columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'F1_EXTRACTION_2021_04_07'\n",
    "filename_meta = 'S_F1_EXTRACTION_2021_04_07'\n",
    "\n",
    "directory_temp = 'C:\\\\Users\\\\NKedrun\\\\Desktop\\\\openHub_arr\\\\' # Не менять\n",
    "directory_report = 'C:\\\\Users\\\\NKedrun\\\\Desktop\\\\' # Не менять Директория в которой появится файл отчета\n",
    "\n",
    "columns_ = ['MATERIAL','/BIC/ZMODUL','/BIC/ZSTCKTGT','/BIC/ZCOMPLEKS','/BIC/ZNSTOR','/BIC/ZBATCHMOD','COMP_CODE'] # Добавлять интересующе стлбцы\n",
    "\n",
    "\n",
    "\n",
    "df = get_report(index_ = ['DATE0'] ,columns_ = columns_,directory_temp=directory_temp,filename = filename,filename_meta = filename_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filters = {'MATERIAL':['911201188'],\n",
    "           'COMP_CODE':['3120']} # фильтр для формирования отчета\n",
    "\n",
    "\n",
    "\n",
    "index_cons = ['MATERIAL','DATE0','/BIC/ZSTCKTGT','COMP_CODE']\n",
    "report  = get_df_pvt_pandas(df = df,index_ = index_cons,columns_=None,filters_ = filters)\n",
    "\n",
    "\n",
    "report.to_excel(directory_report+'open_hub_upload.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['COMP_CODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTrFalse = df.isin(filters)\n",
    "dd = df[getTrFalse]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dd.dropna(axis='index', how='all').index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTrFalse[getTrFalse['MATERIAL'] & getTrFalse['COMP_CODE'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_t = []\n",
    "\n",
    "for ind_ in range(len(arr)):\n",
    "    s = sum(arr[ind_])\n",
    "    if s==2:\n",
    "        ind_t.append(ind_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTrFalse[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {'MATERIAL':['010101012'],'COMP_CODE':['3120']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(getTrFalse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(arr,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr =  np.array(getTrFalse)\n",
    "getTrFalse[np.sum(arr,axis = 1)==len(filters.keys())].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df)==0,'Привет'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
